from datetime import datetime
import hashlib
from urllib.parse import urlparse, urlunparse, parse_qs, urlencode
from typing import List, Optional

from db import get_connection


# --------------------------------------------------------
# URL ì •ê·œí™” í•¨ìˆ˜ ë¶„ë¦¬
# --------------------------------------------------------

def _normalize_common_base(url: str):
    """
    ê³µí†µìœ¼ë¡œ ì“°ëŠ” ê¸°ë³¸ íŒŒì‹±: scheme/host/path ì •ë¦¬
    """
    p = urlparse(url)

    scheme = (p.scheme or "https").lower()
    host = p.netloc.lower()

    path = p.path or "/"
    if path != "/":
        path = path.rstrip("/")

    query = p.query or ""

    return p, scheme, host, path, query


def _remove_tracking_params(raw_query: str) -> str:
    """
    utm_*, gclid ê°™ì€ íŠ¸ë˜í‚¹ íŒŒë¼ë¯¸í„° ì œê±°
    """
    if not raw_query:
        return ""

    raw_params = parse_qs(raw_query, keep_blank_values=True)

    TRACKING_KEYS = {
        "utm_source",
        "utm_medium",
        "utm_campaign",
        "utm_term",
        "utm_content",
        "gclid",
        "fbclid",
        "igshid",
        "mc_eid",
        "mc_cid",
        "ref",
        "ref_src",
    }

    clean_params = {}
    for key, values in raw_params.items():
        kl = key.lower()
        if kl.startswith("utm_"):
            continue
        if kl in TRACKING_KEYS:
            continue
        clean_params[key] = values

    return urlencode(clean_params, doseq=True) if clean_params else ""


# âœ… ê°œì¸ ì°¨ë‹¨ìš© (override):
#    - ë„¤ì´ë²„ ê²€ìƒ‰: queryë§Œ ìœ ì§€
#    - ë„¤ì´ë²„ ë¸”ë¡œê·¸: ì¿¼ë¦¬ ì „ì²´ ë²„ë¦¼
#    - êµ¬ê¸€ ê²€ìƒ‰: që§Œ ìœ ì§€
#    - ê·¸ ì™¸: íŠ¸ë˜í‚¹ë§Œ ì œê±°í•˜ê³  ì¿¼ë¦¬ ì‚´ë¦¼
def normalize_url_for_override(url: str) -> str:
    p, scheme, host, path, query = _normalize_common_base(url)

    # 1) ë„¤ì´ë²„ ê²€ìƒ‰: query íŒŒë¼ë¯¸í„°ë§Œ ìœ ì§€
    if host == "search.naver.com" and path == "/search.naver":
        raw_params = parse_qs(query, keep_blank_values=True)
        clean_params = {}
        if "query" in raw_params:
            clean_params["query"] = raw_params["query"]
        # í•„ìš”í•˜ë©´ where ë“± ì¶”ê°€ ê°€ëŠ¥
        clean_query = urlencode(clean_params, doseq=True) if clean_params else ""
        return urlunparse((scheme, host, path, "", clean_query, ""))

    # 2) ë„¤ì´ë²„ ë¸”ë¡œê·¸: ê¸€ ì£¼ì†Œë§Œìœ¼ë¡œ ì¶©ë¶„ â†’ ì¿¼ë¦¬ ì „ì²´ ì œê±°
    if host in ("blog.naver.com", "m.blog.naver.com"):
        return urlunparse((scheme, host, path, "", "", ""))

    # 3) êµ¬ê¸€ ê²€ìƒ‰: q íŒŒë¼ë¯¸í„°ë§Œ ìœ ì§€ (ê²€ìƒ‰ì–´ë³„ë¡œ êµ¬ë¶„)
    if host in ("www.google.com", "google.com") and path == "/search":
        raw_params = parse_qs(query, keep_blank_values=True)
        clean_params = {}
        if "q" in raw_params:
            clean_params["q"] = raw_params["q"]
        clean_query = urlencode(clean_params, doseq=True) if clean_params else ""
        return urlunparse((scheme, host, path, "", clean_query, ""))

    # 4) ê·¸ ì™¸: íŠ¸ë˜í‚¹ íŒŒë¼ë¯¸í„°ë§Œ ì œê±°í•˜ê³  ë‚˜ë¨¸ì§€ ì¿¼ë¦¬ëŠ” ìœ ì§€
    clean_query = _remove_tracking_params(query)
    return urlunparse((scheme, host, path, "", clean_query, ""))


# âœ… AI ìºì‹œ / ì „ì—­ ì°¨ë‹¨ í•´ì‹œìš©:
#    - ë„¤ì´ë²„ ê²€ìƒ‰: query ê¸°ì¤€ìœ¼ë¡œë§Œ ë¶„ë¦¬
#    - êµ¬ê¸€ ê²€ìƒ‰: q ê¸°ì¤€
#    - ë„¤ì´ë²„ ë¸”ë¡œê·¸: ì¿¼ë¦¬ ì œê±°
#    - ê·¸ ì™¸: íŠ¸ë˜í‚¹ë§Œ ì œê±°í•˜ê³  ì¿¼ë¦¬ ìœ ì§€
def normalize_url_for_cache(url: str) -> str:
    p, scheme, host, path, query = _normalize_common_base(url)

    # 1) ë„¤ì´ë²„ ê²€ìƒ‰: queryë§Œ ê¸°ì¤€ìœ¼ë¡œ ìºì‹œ
    if host == "search.naver.com" and path == "/search.naver":
        raw_params = parse_qs(query, keep_blank_values=True)
        clean_params = {}
        if "query" in raw_params:
            clean_params["query"] = raw_params["query"]
        clean_query = urlencode(clean_params, doseq=True) if clean_params else ""
        return urlunparse((scheme, host, path, "", clean_query, ""))

    # 2) êµ¬ê¸€ ê²€ìƒ‰: q ê¸°ë°˜ìœ¼ë¡œ ë‚˜ëˆ”
    if host in ("www.google.com", "google.com") and path == "/search":
        raw_params = parse_qs(query, keep_blank_values=True)
        clean_params = {}
        if "q" in raw_params:
            clean_params["q"] = raw_params["q"]
        clean_query = urlencode(clean_params, doseq=True) if clean_params else ""
        return urlunparse((scheme, host, path, "", clean_query, ""))

    # 3) ë„¤ì´ë²„ ë¸”ë¡œê·¸ëŠ” ìºì‹œì—ì„œë„ êµ³ì´ ì¿¼ë¦¬ë¥¼ ìœ ì§€í•  í•„ìš”ê°€ ê±°ì˜ ì—†ìŒ â†’ ê¸€ ë‹¨ìœ„
    if host in ("blog.naver.com", "m.blog.naver.com"):
        return urlunparse((scheme, host, path, "", "", ""))

    # 4) ë‚˜ë¨¸ì§€ëŠ” íŠ¸ë˜í‚¹ë§Œ ì œê±°í•˜ê³  ì¿¼ë¦¬ ìœ ì§€ (ê²€ìƒ‰ì–´/í•„í„°ë³„ ìºì‹œ ë¶„ë¦¬)
    clean_query = _remove_tracking_params(query)
    return urlunparse((scheme, host, path, "", clean_query, ""))


# âœ… ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ìš© (ê°œì¸ ì˜¤ë²„ë¼ì´ë“œ ê¸°ì¤€)
def normalize_url(url: str) -> str:
    return normalize_url_for_override(url)


# SHA256 í•´ì‹œ
def _make_url_hash(normalized_url: str) -> bytes:
    return hashlib.sha256(normalized_url.encode("utf-8")).digest()


# --------------------------------------------------------
# user_id ìƒì„±
# --------------------------------------------------------
def _get_or_create_user_id(client_id: str) -> int:
    conn = get_connection()
    if not conn:
        raise Exception("[_get_or_create_user_id] DB ì—°ê²° ì‹¤íŒ¨")

    try:
        with conn.cursor() as cursor:
            cursor.execute(
                "SELECT id FROM users WHERE external_id=%s LIMIT 1",
                (client_id,),
            )
            row = cursor.fetchone()
            if row:
                return row["id"]

            cursor.execute(
                "INSERT INTO users (display_name, external_id, created_at) VALUES (%s,%s,%s)",
                ("", client_id, datetime.now()),
            )
            conn.commit()
            return conn.insert_id() if hasattr(conn, "insert_id") else cursor.lastrowid
    finally:
        conn.close()


# --------------------------------------------------------
# ğŸ”¥ ì „ì—­ ì°¨ë‹¨ ë“±ë¡ (AI ì´ìœ  + ì¶”ì²œ URL ì €ì¥)
# --------------------------------------------------------
def add_global_block(
    url: str,
    ai_reason: Optional[str] = None,
    suggested_url: Optional[str] = None,
) -> bool:
    conn = get_connection()
    if not conn:
        print("[add_global_block] DB ì—°ê²° ì‹¤íŒ¨")
        return False

    # DBì—ëŠ” ì§§ì€ ë²„ì „ (override ê¸°ì¤€) ì €ì¥
    normalized_db = normalize_url_for_override(url)
    # í•´ì‹œëŠ” ìºì‹œ ê¸°ì¤€(ê²€ìƒ‰ì–´ í¬í•¨)ìœ¼ë¡œ ìƒì„±
    normalized_for_hash = normalize_url_for_cache(url)
    url_hash = _make_url_hash(normalized_for_hash)

    try:
        with conn.cursor() as cursor:
            sql = """
            INSERT INTO phishing_sites (
                normalized_url,
                url_hash,
                is_blocked,
                ai_reason,
                suggested_official_url,
                created_at
            )
            VALUES (%s, %s, 1, %s, %s, %s)
            ON DUPLICATE KEY UPDATE
                is_blocked = 1,
                ai_reason = VALUES(ai_reason),
                suggested_official_url = VALUES(suggested_official_url),
                created_at = VALUES(created_at)
            """
            cursor.execute(
                sql,
                (normalized_db, url_hash, ai_reason, suggested_url, datetime.now()),
            )
        conn.commit()
        return True
    except Exception as e:
        print("[add_global_block] ì—ëŸ¬:", e)
        return False
    finally:
        conn.close()


# --------------------------------------------------------
# URL ì°¨ë‹¨ ì—¬ë¶€ í™•ì¸
#   ë°˜í™˜ê°’:
#   2 = ì „ì—­ ì°¨ë‹¨ (phishing_sites: ë„ë©”ì¸/URL)
#   1 = ê°œì¸ ì°¨ë‹¨ (user_url_overrides, decision=1)
#   0 = ì°¨ë‹¨ ì•„ë‹˜ / í—ˆìš©
# --------------------------------------------------------
def check_url(client_id: str, url: str) -> int:
    # ë‘ ê°€ì§€ ê¸°ì¤€ìœ¼ë¡œ ë”°ë¡œ ì •ê·œí™”
    normalized_override = normalize_url_for_override(url)  # ê°œì¸ ì˜¤ë²„ë¼ì´ë“œìš©
    url_hash_override = _make_url_hash(normalized_override)

    normalized_cache = normalize_url_for_cache(url)        # ì „ì—­/ìºì‹œìš©
    url_hash_cache = _make_url_hash(normalized_cache)

    # user ìƒì„± ë˜ëŠ” ì¡°íšŒ
    try:
        user_id = _get_or_create_user_id(client_id)
    except Exception:
        return 0

    conn = get_connection()
    if not conn:
        print("[check_url] DB ì—°ê²° ì‹¤íŒ¨")
        return 0

    try:
        with conn.cursor() as cursor:
            # 0) ì „ì—­ ë„ë©”ì¸ ì°¨ë‹¨
            host = urlparse(normalized_cache).netloc.lower()

            cursor.execute(
                """
                SELECT 1
                FROM phishing_sites
                WHERE is_domain_block = 1
                  AND (
                        domain = %s
                     OR %s LIKE CONCAT('%%.', domain)
                  )
                LIMIT 1
                """,
                (host, host),
            )
            row = cursor.fetchone()
            if row:
                return 2

            # 1) ì „ì—­ URL ì°¨ë‹¨ (AI/GSB)
            cursor.execute(
                "SELECT is_blocked FROM phishing_sites WHERE url_hash=%s LIMIT 1",
                (url_hash_cache,),
            )
            row = cursor.fetchone()
            if row and int(row["is_blocked"]) == 1:
                return 2

            # 2) ê°œì¸ ì˜¤ë²„ë¼ì´ë“œ
            cursor.execute(
                """
                SELECT decision
                FROM user_url_overrides
                WHERE user_id=%s AND url_hash=%s
                LIMIT 1
                """,
                (user_id, url_hash_override),
            )
            row = cursor.fetchone()
            if row is not None:
                return int(row["decision"])

            # 3) ê¸°ë³¸ í—ˆìš©
            return 0

    except Exception as e:
        print("[check_url] ì—ëŸ¬:", e)
        return 0
    finally:
        conn.close()


# --------------------------------------------------------
# ì‹ ê³  (ì‚¬ìš©ì â†’ ìˆ˜ë™ ì‹ ê³ )
# --------------------------------------------------------
def report_url(client_id: str, url: str) -> bool:
    try:
        user_id = _get_or_create_user_id(client_id)
    except Exception:
        return False

    conn = get_connection()
    if not conn:
        print("[report_url] DB ì—°ê²° ì‹¤íŒ¨")
        return False

    normalized_url = normalize_url_for_override(url)
    url_hash = _make_url_hash(normalized_url)

    try:
        with conn.cursor() as cursor:
            cursor.execute(
                """
                INSERT INTO reported_urls (reporter_user_id, normalized_url, url_hash, created_at)
                VALUES (%s, %s, %s, %s)
                """,
                (user_id, normalized_url, url_hash, datetime.now()),
            )
        conn.commit()
        return True
    except Exception as e:
        print("[report_url] ì—ëŸ¬:", e)
        return False
    finally:
        conn.close()


# --------------------------------------------------------
# ê°œì¸ ì°¨ë‹¨
# --------------------------------------------------------
def override_url(client_id: str, normalized_url: str, decision: int) -> bool:
    try:
        user_id = _get_or_create_user_id(client_id)
    except Exception:
        return False

    conn = get_connection()
    if not conn:
        print("[override_url] DB ì—°ê²° ì‹¤íŒ¨")
        return False

    normalized_url = normalize_url_for_override(normalized_url)
    url_hash = _make_url_hash(normalized_url)

    try:
        with conn.cursor() as cursor:
            cursor.execute(
                """
                INSERT INTO user_url_overrides (user_id, normalized_url, url_hash, decision, created_at)
                VALUES (%s, %s, %s, %s, %s)
                ON DUPLICATE KEY UPDATE
                    decision = VALUES(decision),
                    normalized_url = VALUES(normalized_url),
                    created_at = VALUES(created_at)
                """,
                (user_id, normalized_url, url_hash, decision, datetime.now()),
            )
        conn.commit()
        return True
    except Exception as e:
        print("[override_url] ì—ëŸ¬:", e)
        return False
    finally:
        conn.close()


# --------------------------------------------------------
# ê°œì¸ ì°¨ë‹¨ í•´ì œ
# --------------------------------------------------------
def remove_override_url(client_id: str, normalized_url: str) -> bool:
    try:
        user_id = _get_or_create_user_id(client_id)
    except Exception:
        return False

    conn = get_connection()
    if not conn:
        print("[remove_override_url] DB ì—°ê²° ì‹¤íŒ¨")
        return False

    normalized_url = normalize_url_for_override(normalized_url)
    url_hash = _make_url_hash(normalized_url)

    try:
        with conn.cursor() as cursor:
            cursor.execute(
                "DELETE FROM user_url_overrides WHERE user_id=%s AND url_hash=%s",
                (user_id, url_hash),
            )
        conn.commit()
        return cursor.rowcount > 0
    except Exception as e:
        print("[remove_override_url] ì—ëŸ¬:", e)
        return False
    finally:
        conn.close()


# --------------------------------------------------------
# ê°œì¸ ì°¨ë‹¨ ëª©ë¡
# --------------------------------------------------------
def get_user_blocked_urls(client_id: str) -> List[str]:
    try:
        user_id = _get_or_create_user_id(client_id)
    except Exception:
        return []

    conn = get_connection()
    if not conn:
        print("[get_user_blocked_urls] DB ì—°ê²° ì‹¤íŒ¨")
        return []

    try:
        with conn.cursor() as cursor:
            cursor.execute(
                """
                SELECT normalized_url
                FROM user_url_overrides
                WHERE user_id=%s AND decision=1
                ORDER BY created_at DESC
                """,
                (user_id,),
            )
            rows = cursor.fetchall() or []
            return [row["normalized_url"] for row in rows]
    except Exception as e:
        print("[get_user_blocked_urls] ì—ëŸ¬:", e)
        return []
    finally:
        conn.close()


# --------------------------------------------------------
# AI / GSB ìºì‹œ ì¡°íšŒ
# --------------------------------------------------------
def get_ai_cache(url: str, max_age_days: int = 30) -> Optional[dict]:
    conn = get_connection()
    if not conn:
        print("[get_ai_cache] DB ì—°ê²° ì‹¤íŒ¨")
        return None

    normalized_for_hash = normalize_url_for_cache(url)
    url_hash = _make_url_hash(normalized_for_hash)

    try:
        with conn.cursor() as cursor:
            sql = """
            SELECT
                gsb_status,
                ai_score,
                ai_reason,
                suggested_official_url,
                updated_at
            FROM ai_cache
            WHERE url_hash = %s
              AND updated_at >= (NOW() - INTERVAL %s DAY)
            LIMIT 1
            """
            cursor.execute(sql, (url_hash, max_age_days))
            row = cursor.fetchone()
            if not row:
                return None

            return {
                "gsb_status": row["gsb_status"],
                "ai_score": row["ai_score"],
                "ai_reason": row["ai_reason"],
                "suggested_official_url": row["suggested_official_url"],
            }
    except Exception as e:
        print("[get_ai_cache] ì—ëŸ¬:", e)
        return None
    finally:
        conn.close()


# --------------------------------------------------------
# AI / GSB ìºì‹œ ì €ì¥ or ê°±ì‹ 
# --------------------------------------------------------
def upsert_ai_cache(
    url: str,
    gsb_status: Optional[int] = None,
    ai_score: Optional[int] = None,
    ai_reason: Optional[str] = None,
    suggested_url: Optional[str] = None,
) -> bool:
    conn = get_connection()
    if not conn:
        print("[upsert_ai_cache] DB ì—°ê²° ì‹¤íŒ¨")
        return False

    normalized_db = normalize_url_for_override(url)
    normalized_for_hash = normalize_url_for_cache(url)
    url_hash = _make_url_hash(normalized_for_hash)
    now = datetime.now()

    # gsb_status ë¬¸ìì—´ ë“¤ì–´ì™€ë„ ì•ˆì „í•˜ê²Œ ìˆ«ìë¡œ ë³€í™˜
    gsb_value: Optional[int]
    if isinstance(gsb_status, str):
        upper = gsb_status.upper()
        if upper == "SAFE":
            gsb_value = 0
        elif upper in ("DANGEROUS", "UNSAFE", "MALICIOUS"):
            gsb_value = 1
        else:
            gsb_value = None
    else:
        gsb_value = gsb_status

    try:
        with conn.cursor() as cursor:
            sql = """
            INSERT INTO ai_cache (
                normalized_url,
                url_hash,
                gsb_status,
                ai_score,
                ai_reason,
                suggested_official_url,
                updated_at
            )
            VALUES (%s, %s, %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE
                gsb_status = VALUES(gsb_status),
                ai_score = VALUES(ai_score),
                ai_reason = VALUES(ai_reason),
                suggested_official_url = VALUES(suggested_official_url),
                updated_at = VALUES(updated_at)
            """
            cursor.execute(
                sql,
                (normalized_db, url_hash, gsb_value, ai_score, ai_reason, suggested_url, now),
            )
        conn.commit()
        return True
    except Exception as e:
        print("[upsert_ai_cache] ì—ëŸ¬:", e)
        return False
    finally:
        conn.close()
